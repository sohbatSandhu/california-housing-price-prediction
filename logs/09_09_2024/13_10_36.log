[2024-09-09 13:10:38,147] 27 root - INFO - Data Ingestion initiated
[2024-09-09 13:10:38,147] 150 root - INFO - Data already downloaded
[2024-09-09 13:10:38,289] 62 root - INFO - Train test split initated
[2024-09-09 13:10:38,408] 69 root - INFO - Ingestion of the data is completed
[2024-09-09 13:10:38,425] 75 root - INFO - Reading train and test data completed
[2024-09-09 13:10:38,425] 77 root - INFO - Obtaining preprocessing object
[2024-09-09 13:10:38,425] 36 root - INFO - Categorical columns: ['ocean_proximity']
[2024-09-09 13:10:38,425] 37 root - INFO - Numerical columns: ['longitude', 'latitude', 'housing_median_age', 'total_bedrooms', 'total_rooms', 'population', 'households', 'median_income']
[2024-09-09 13:10:38,425] 45 root - INFO - Built Imputer
[2024-09-09 13:10:38,426] 63 root - INFO - Built Preprocesser
[2024-09-09 13:10:38,428] 89 root - INFO - Applying preprocessing object on training dataframe and testing dataframe.
[2024-09-09 13:10:38,454] 101 root - INFO - Imputation Performed
[2024-09-09 13:10:38,459] 112 root - INFO - Perform feature engineering
[2024-09-09 13:10:38,461] 118 root - INFO - Engineered Features: ['rooms_per_household', 'bedrooms_per_rooms', 'bedrooms_per_households', 'population_per_household']
[2024-09-09 13:10:38,462] 119 root - INFO - Perform Log transformation on Highly skewed features
[2024-09-09 13:10:38,466] 125 root - INFO - Log transformed Features: ['total_bedrooms', 'total_rooms', 'population', 'households', 'rooms_per_household', 'bedrooms_per_rooms', 'bedrooms_per_households', 'population_per_household']
[2024-09-09 13:10:38,492] 143 root - INFO - Saved imputer object.
[2024-09-09 13:10:38,492] 149 root - INFO - Saved feature engineering object.
[2024-09-09 13:10:38,493] 155 root - INFO - Saved Log transformer object.
[2024-09-09 13:10:38,495] 161 root - INFO - Saved preprocessing object.
[2024-09-09 13:10:38,497] 29 root - INFO - Split training and test input data
[2024-09-09 13:10:38,497] 37 root - INFO - Initialize models and hyper-parameters
[2024-09-09 13:10:38,497] 41 root - INFO - Evaluating Models on pre-processed training data
[2024-09-09 13:10:42,845] 114 root - INFO - Best LinearRegression() model evaluated with best parameters {} getting training score of 0.6726144887532944
[2024-09-09 13:10:43,682] 114 root - INFO - Best Ridge() model evaluated with best parameters {'alpha': 1.0} getting training score of 0.6727514022694606
[2024-09-09 13:10:45,476] 114 root - INFO - Best DecisionTreeRegressor(max_depth=10, min_samples_split=10) model evaluated with best parameters {'max_depth': 10, 'min_samples_split': 10} getting training score of 0.7078441136145951
[2024-09-09 13:17:36,187] 114 root - INFO - Best RandomForestRegressor(min_samples_split=5, n_estimators=300) model evaluated with best parameters {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 300} getting training score of 0.8065671627717022
[2024-09-09 13:19:27,664] 114 root - INFO - Best BaggingRegressor(max_features=0.8, n_estimators=100) model evaluated with best parameters {'max_features': 0.8, 'max_samples': 1.0, 'n_estimators': 100} getting training score of 0.8193691807297575
[2024-09-09 13:25:02,367] 114 root - INFO - Best GradientBoostingRegressor(max_depth=7, n_estimators=300) model evaluated with best parameters {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300} getting training score of 0.8334931219696164
[2024-09-09 13:26:11,520] 114 root - INFO - Best AdaBoostRegressor(learning_rate=0.1, loss='exponential') model evaluated with best parameters {'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 50} getting training score of 0.634487064883724
[2024-09-09 13:46:32,849] 114 root - INFO - Best XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=0, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.1, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=5, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=500, n_jobs=None,
             num_parallel_tree=None, random_state=None, ...) model evaluated with best parameters {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500, 'reg_alpha': 0.1, 'reg_lambda': 2} getting training score of 0.8418282798338635
[2024-09-09 13:46:32,850] 65 root - INFO - Best Model found on training and testing dataset
[2024-09-09 13:46:33,264] 72 root - INFO - Saved Best Model
[2024-09-09 13:46:33,398] 77 root - INFO - Best Model Score on Test Data: 0.8158380276774695
